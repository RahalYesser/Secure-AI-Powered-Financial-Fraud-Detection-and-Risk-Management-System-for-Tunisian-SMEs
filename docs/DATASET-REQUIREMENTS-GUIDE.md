# üìä COMPLETE DATASET REQUIREMENTS GUIDE FOR AI FRAUD DETECTION

## Executive Summary

This guide explains **everything** you need to know about datasets for your AI fraud detection models:
- What datasets to use
- Required vs optional columns
- How to handle column name mismatches
- Dataset size recommendations
- Whether each AI model needs separate datasets
- How to prepare and use datasets

---

## PART 1: DATASET FUNDAMENTALS

### 1.1 Do You Need Separate Datasets for Each Model?

**Answer: NO, you use ONE dataset for all models ‚úÖ**

**Why?**
- DJL, ONNX, and TensorFlow are **inference engines**, not training frameworks
- You train models in **Python**, then export to formats that these engines can load
- All three models learn from the **same historical transaction data**

**Workflow:**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   ONE UNIFIED DATASET                   ‚îÇ
‚îÇ   (transactions.csv)                    ‚îÇ
‚îÇ   - All historical transactions         ‚îÇ
‚îÇ   - Features + fraud labels             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ
             ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
             ‚ñº                      ‚ñº                      ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ Train Model 1  ‚îÇ    ‚îÇ Train Model 2  ‚îÇ    ‚îÇ Train Model 3  ‚îÇ
    ‚îÇ (PyTorch)      ‚îÇ    ‚îÇ (Scikit-learn) ‚îÇ    ‚îÇ (TensorFlow)   ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ                      ‚îÇ                      ‚îÇ
             ‚ñº                      ‚ñº                      ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ Export to      ‚îÇ    ‚îÇ Export to      ‚îÇ    ‚îÇ Export to      ‚îÇ
    ‚îÇ PyTorch (.pt)  ‚îÇ    ‚îÇ ONNX (.onnx)   ‚îÇ    ‚îÇ SavedModel     ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ                      ‚îÇ                      ‚îÇ
             ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                   ‚îÇ
                        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                        ‚îÇ   Java Application   ‚îÇ
                        ‚îÇ   - DJL loads .pt    ‚îÇ
                        ‚îÇ   - ONNX loads .onnx ‚îÇ
                        ‚îÇ   - TF loads model   ‚îÇ
                        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Key Point:** Different models (Random Forest, Neural Network, XGBoost) trained on the same data provide **diverse perspectives** = better ensemble accuracy

---

## PART 2: DATASET REQUIREMENTS

### 2.1 Recommended Datasets

#### **Option 1: IEEE-CIS Fraud Detection Dataset** ‚≠ê BEST CHOICE

**Source:** Kaggle - [IEEE-CIS Fraud Detection](https://www.kaggle.com/c/ieee-fraud-detection)

**Size:**
- 590,540 transactions
- 434 features (identity + transaction features)
- 3.5% fraud rate (realistic)

**Why this dataset?**
- ‚úÖ Real-world credit card transactions
- ‚úÖ Rich feature set (device, IP, card info)
- ‚úÖ Imbalanced classes (like real fraud)
- ‚úÖ Industry-standard benchmark

**Columns (subset):**
```csv
TransactionID,TransactionDT,TransactionAmt,ProductCD,card1,card2,card3,card4,card5,card6,
addr1,addr2,dist1,dist2,P_emaildomain,R_emaildomain,C1,C2,C3,C4,C5,C6,C7,C8,C9,C10,C11,C12,C13,C14,
D1,D2,D3,D4,D5,D6,D7,D8,D9,D10,D11,D12,D13,D14,D15,
M1,M2,M3,M4,M5,M6,M7,M8,M9,
V1,V2,V3,...,V339,
isFraud
```

---

#### **Option 2: Credit Card Fraud Detection Dataset** ‚≠ê GOOD FOR TESTING

**Source:** Kaggle - [Credit Card Fraud Detection](https://www.kaggle.com/mlg-ulb/creditcardfraud)

**Size:**
- 284,807 transactions
- 31 features (28 PCA-transformed + Time, Amount, Class)
- 0.17% fraud rate

**Why this dataset?**
- ‚úÖ Clean and preprocessed
- ‚úÖ Easy to get started
- ‚úÖ Well-documented
- ‚ö†Ô∏è Features are PCA-transformed (anonymized)

**Columns:**
```csv
Time,V1,V2,V3,V4,V5,V6,V7,V8,V9,V10,V11,V12,V13,V14,V15,V16,V17,V18,V19,V20,V21,V22,V23,V24,V25,V26,V27,V28,Amount,Class
```

---

#### **Option 3: Synthetic Financial Transactions** (For Testing Only)

**When to use:**
- You don't have access to real data
- Quick prototyping/testing
- Educational purposes

**How to generate:**
```python
import pandas as pd
import numpy as np
from datetime import datetime, timedelta

np.random.seed(42)
n_samples = 100000

# Generate synthetic transactions
data = {
    'transaction_id': range(1, n_samples + 1),
    'amount': np.random.lognormal(6, 2, n_samples),  # Log-normal distribution (realistic)
    'hour': np.random.randint(0, 24, n_samples),
    'day_of_week': np.random.randint(0, 7, n_samples),
    'transaction_type': np.random.choice([0, 1, 2, 3], n_samples),  # PAYMENT, TRANSFER, WITHDRAWAL, DEPOSIT
    'user_age_days': np.random.randint(0, 3650, n_samples),
    'user_transaction_count': np.random.randint(1, 500, n_samples),
    'is_weekend': np.random.randint(0, 2, n_samples),
}

# Create fraud labels (2% fraud rate)
def generate_fraud_label(row):
    score = 0
    if row['amount'] > 10000: score += 0.4
    if row['hour'] < 6 or row['hour'] > 22: score += 0.3
    if row['is_weekend'] == 1: score += 0.2
    if row['transaction_type'] == 2: score += 0.1  # WITHDRAWAL
    
    # Add randomness
    score += np.random.uniform(-0.2, 0.2)
    
    return 1 if score > 0.6 else 0

df = pd.DataFrame(data)
df['is_fraud'] = df.apply(generate_fraud_label, axis=1)

df.to_csv('synthetic_transactions.csv', index=False)
print(f"Generated {n_samples} transactions with {df['is_fraud'].sum()} fraud cases ({df['is_fraud'].mean()*100:.2f}%)")
```

---

### 2.2 CRITICAL: Required vs Optional Columns

#### **REQUIRED Columns (Must Have):**

| Column | Description | Type | Why Required |
|--------|-------------|------|--------------|
| `transaction_id` or `id` | Unique identifier | Integer/String | Track individual transactions |
| `amount` | Transaction value | Float | **Primary fraud indicator** |
| `timestamp` or `date` | When transaction occurred | DateTime | Extract time-based features |
| `is_fraud` or `class` or `label` | Fraud label | Binary (0/1) | **Ground truth for training** |

**Minimum viable dataset:**
```csv
transaction_id,amount,timestamp,is_fraud
1,5000.50,2024-01-15 14:30:00,0
2,15000.00,2024-01-15 03:45:00,1
3,2500.75,2024-01-15 10:20:00,0
...
```

---

#### **HIGHLY RECOMMENDED Columns:**

| Column | Description | Fraud Signal Strength | Your Entities |
|--------|-------------|----------------------|---------------|
| `transaction_type` | PAYMENT/WITHDRAWAL/etc | ‚≠ê‚≠ê‚≠ê Medium | `Transaction.type` |
| `user_id` | User identifier | ‚≠ê‚≠ê‚≠ê‚≠ê High | `Transaction.user.id` |
| `hour` or extract from timestamp | Hour of day (0-23) | ‚≠ê‚≠ê‚≠ê‚≠ê High | Extract from `created_at` |
| `day_of_week` | 0=Monday, 6=Sunday | ‚≠ê‚≠ê‚≠ê Medium | Extract from `created_at` |
| `status` | PENDING/COMPLETED/etc | ‚≠ê‚≠ê Low | `Transaction.status` |

---

#### **OPTIONAL But Valuable Columns:**

| Column | Fraud Signal | Example Values |
|--------|-------------|----------------|
| `merchant_category` | ‚≠ê‚≠ê‚≠ê‚≠ê | electronics, gambling, travel |
| `card_number` (hashed) | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Multiple transactions same card |
| `ip_address` (hashed) | ‚≠ê‚≠ê‚≠ê‚≠ê | Geolocation matching |
| `device_id` | ‚≠ê‚≠ê‚≠ê‚≠ê | New device detection |
| `email_domain` | ‚≠ê‚≠ê‚≠ê | Temporary email detection |
| `billing_country` | ‚≠ê‚≠ê‚≠ê‚≠ê | Cross-border anomalies |
| `shipping_country` | ‚≠ê‚≠ê‚≠ê‚≠ê | Address mismatch |
| `currency` | ‚≠ê‚≠ê | Currency conversion fraud |
| `user_age_days` | ‚≠ê‚≠ê‚≠ê | New account risk |
| `previous_transaction_count` | ‚≠ê‚≠ê‚≠ê‚≠ê | User behavior history |
| `average_transaction_amount` | ‚≠ê‚≠ê‚≠ê‚≠ê | Deviation detection |
| `failed_login_attempts` | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Account takeover |

**The more features, the better!** Modern ML models handle 100+ features easily.

---

### 2.3 Handling Column Name Mismatches

**Question:** What if dataset columns don't match my `Transaction` entity?

**Answer: NO PROBLEM! You'll map them during feature extraction ‚úÖ**

#### **Example Scenario:**

**Your Transaction Entity:**
```java
public class Transaction {
    private Long id;
    private BigDecimal amount;
    private TransactionType type;      // Enum: PAYMENT, TRANSFER, WITHDRAWAL, DEPOSIT
    private TransactionStatus status;
    private Instant createdAt;
    private User user;
    // ...
}
```

**Dataset Columns (IEEE-CIS):**
```csv
TransactionID,TransactionDT,TransactionAmt,ProductCD,isFraud
12345,86400,100.50,W,0
```

**Mapping Strategy:**

```java
private float[] extractFeatures(Transaction transaction) {
    // Map YOUR entity ‚Üí MODEL features
    
    float amount = transaction.getAmount().floatValue();  // ‚úÖ Direct mapping
    
    // Extract time features from createdAt
    ZonedDateTime zdt = transaction.getCreatedAt().atZone(ZoneId.systemDefault());
    float hour = zdt.getHour();                           // ‚úÖ Derived feature
    float dayOfWeek = zdt.getDayOfWeek().getValue();      // ‚úÖ Derived feature
    float dayOfMonth = zdt.getDayOfMonth();               // ‚úÖ Derived feature
    
    // Convert enum to numerical
    float typeValue = transaction.getType().ordinal();    // ‚úÖ Enum mapping
    float statusValue = transaction.getStatus().ordinal(); // ‚úÖ Enum mapping
    
    // User-related features (if User entity loaded)
    float userAgeDays = 0;
    float userTxCount = 0;
    float userAvgAmount = 0;
    
    if (transaction.getUser() != null) {
        User user = transaction.getUser();
        userAgeDays = java.time.Duration.between(
            user.getCreatedAt(), Instant.now()
        ).toDays();  // ‚úÖ Calculated from User entity
        
        // Query repository for user statistics
        userTxCount = transactionRepository.countByUserId(user.getId());
        BigDecimal avgAmt = transactionRepository.getAverageAmountByUserId(user.getId());
        userAvgAmount = avgAmt != null ? avgAmt.floatValue() : 0;
    }
    
    return new float[]{
        amount,           // Feature 0
        hour,             // Feature 1
        dayOfWeek,        // Feature 2
        dayOfMonth,       // Feature 3
        typeValue,        // Feature 4
        statusValue,      // Feature 5
        userAgeDays,      // Feature 6
        userTxCount,      // Feature 7
        userAvgAmount     // Feature 8
    };
}
```

**Key Principle:** 
> **Your Java entity structure does NOT need to match dataset columns.**  
> Feature extraction is the bridge between your database schema and ML model input.

---

### 2.4 Is Having Extra Columns a Problem?

**Question:** Dataset has 434 columns, but I only use 10 features. Is this a problem?

**Answer: NO! Extra columns are GOOD ‚úÖ**

**Why extra columns are beneficial:**

1. **Feature Selection During Training:**
   ```python
   # Python training code
   import pandas as pd
   from sklearn.ensemble import RandomForestClassifier
   
   # Load full dataset with 434 columns
   df = pd.read_csv('ieee-cis-fraud.csv')
   
   # Select only features you need
   features_to_use = [
       'TransactionAmt',     # ‚Üí amount
       'hour',               # ‚Üí extracted from TransactionDT
       'day_of_week',        # ‚Üí extracted from TransactionDT
       'ProductCD',          # ‚Üí transaction type
       'card1',              # ‚Üí card info (if available)
       'addr1',              # ‚Üí billing address
       'C1', 'C2', 'C3',     # ‚Üí count features
       'D1', 'D2',           # ‚Üí time delta features
   ]
   
   X = df[features_to_use]
   y = df['isFraud']
   
   model = RandomForestClassifier()
   model.fit(X, y)
   ```

2. **Future Expansion:**
   - Start with 10 features
   - Model accuracy not good enough?
   - Add more features from dataset (card info, device, IP, etc.)
   - Retrain model
   - No need to collect new data!

3. **Ignore Unused Columns:**
   ```python
   # Dataset has 434 columns
   df = pd.read_csv('ieee-cis-fraud.csv')  
   
   # Use only 10
   X = df[['TransactionAmt', 'hour', 'day_of_week', ...]]  # 10 columns
   
   # Remaining 424 columns are ignored (no problem)
   ```

**Best Practice:**
- Download full dataset
- Start with basic features (10-15)
- Iterate and add more features as needed

---

## PART 3: DATASET SIZE RECOMMENDATIONS

### 3.1 Minimum vs Optimal Dataset Size

| Use Case | Minimum Size | Optimal Size | Fraud Cases Needed |
|----------|-------------|--------------|-------------------|
| **Testing/Prototyping** | 1,000 rows | 10,000 rows | 20-50 fraud cases |
| **Development** | 10,000 rows | 50,000 rows | 100-200 fraud cases |
| **Production (Simple)** | 50,000 rows | 100,000 rows | 500-1,000 fraud cases |
| **Production (Advanced)** | 100,000 rows | 500,000+ rows | 2,000-10,000 fraud cases |

### 3.2 Why Dataset Size Matters

**Problem: Class Imbalance**
```
Real-world fraud rate: 0.5% - 2%

If you have 10,000 transactions:
- Fraud cases: 10,000 √ó 0.01 = 100 fraud transactions
- Legitimate: 9,900 transactions

100 fraud cases = barely enough to learn patterns
```

**Solution: Larger dataset or oversampling**
```
Option 1: Get 100,000 transactions
- Fraud: 1,000 cases (enough to train)
- Legitimate: 99,000 cases

Option 2: Use SMOTE (Synthetic Minority Oversampling)
from imblearn.over_sampling import SMOTE

smote = SMOTE()
X_resampled, y_resampled = smote.fit_resample(X, y)
# Now you have balanced classes
```

### 3.3 Data Split Strategy

```
Total Dataset (100,000 transactions)
‚îÇ
‚îú‚îÄ Training Set (70%) = 70,000 transactions
‚îÇ  ‚îî‚îÄ Used to train model
‚îÇ
‚îú‚îÄ Validation Set (15%) = 15,000 transactions
‚îÇ  ‚îî‚îÄ Used to tune hyperparameters
‚îÇ
‚îî‚îÄ Test Set (15%) = 15,000 transactions
   ‚îî‚îÄ Used to evaluate final model (never seen during training)
```

**Important:** Ensure all three sets have similar fraud rates!

---

## PART 4: CHOOSING THE RIGHT DATASET

### 4.1 Decision Matrix

**Your Project:** Tunisian SME Financial System

| Dataset | Pros | Cons | Recommendation |
|---------|------|------|----------------|
| **IEEE-CIS** | ‚úÖ 590K transactions<br>‚úÖ Rich features<br>‚úÖ Real-world data | ‚ùå Large download (10GB)<br>‚ùå Credit card focus (not SME-specific) | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê **BEST CHOICE** |
| **Kaggle Credit Card** | ‚úÖ Easy to use<br>‚úÖ Clean data<br>‚úÖ Quick download | ‚ùå Only 284K transactions<br>‚ùå Features anonymized (V1-V28) | ‚≠ê‚≠ê‚≠ê‚≠ê GOOD |
| **Synthetic** | ‚úÖ Instant<br>‚úÖ Customizable<br>‚úÖ No privacy issues | ‚ùå Not real fraud patterns<br>‚ùå Lower accuracy | ‚≠ê‚≠ê TESTING ONLY |
| **Collect your own** | ‚úÖ Perfect fit for your system<br>‚úÖ Tunisian SME-specific | ‚ùå Takes 6-12 months<br>‚ùå Needs labeling | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê **LONG TERM** |

### 4.2 Recommendation for Your Project

**Phase 1 (NOW - Testing): Use IEEE-CIS Dataset**
```bash
# Download from Kaggle
kaggle competitions download -c ieee-fraud-detection

# Unzip
unzip ieee-fraud-detection.zip

# Files you need:
# - train_transaction.csv (590,540 rows)
# - train_identity.csv (144,233 rows)
```

**Why?**
- Get started immediately
- Train production-quality models
- Learn what features matter most
- Build your ML pipeline

**Phase 2 (6-12 months later): Collect Your Own Data**
```java
@Service
public class TransactionDataCollectionService {
    
    @EventListener
    public void onTransactionCreated(TransactionCreatedEvent event) {
        // Store for ML training
        MLTrainingDataset record = MLTrainingDataset.builder()
            .transaction(event.getTransaction())
            .features(extractAllFeatures(event.getTransaction()))
            .label(null)  // Will be labeled after investigation
            .build();
        
        mlDatasetRepository.save(record);
    }
    
    @Scheduled(cron = "0 0 1 * * ?")  // Daily at 1 AM
    public void exportTrainingData() {
        // Export last 30 days of transactions
        List<MLTrainingDataset> data = mlDatasetRepository.findLast30Days();
        csvExporter.export(data, "tunisian_sme_fraud_" + LocalDate.now() + ".csv");
    }
}
```

**After 1 year:**
- You have 50,000-100,000 real Tunisian SME transactions
- Manually labeled fraud cases
- Retrain models on YOUR data
- Accuracy improves by 20-30%

---

## PART 5: PRACTICAL IMPLEMENTATION

### 5.1 How to Use Kaggle Datasets

**Step 1: Download IEEE-CIS Dataset**
```bash
# Install Kaggle CLI
pip install kaggle

# Configure API credentials
mkdir ~/.kaggle
cp kaggle.json ~/.kaggle/
chmod 600 ~/.kaggle/kaggle.json

# Download dataset
kaggle competitions download -c ieee-fraud-detection

# Extract
unzip ieee-fraud-detection.zip
```

**Step 2: Explore the Dataset**
```python
import pandas as pd

# Load transaction data
train_tx = pd.read_csv('train_transaction.csv')

print(f"Shape: {train_tx.shape}")
print(f"Fraud rate: {train_tx['isFraud'].mean()*100:.2f}%")
print(f"Columns: {train_tx.columns.tolist()}")

# Check for missing values
print(train_tx.isnull().sum())

# Basic statistics
print(train_tx[['TransactionAmt', 'isFraud']].describe())
```

**Output:**
```
Shape: (590540, 394)
Fraud rate: 3.50%
Columns: ['TransactionID', 'isFraud', 'TransactionDT', 'TransactionAmt', 'ProductCD', ...]

TransactionAmt:
  mean:     93.82
  std:     131.68
  min:       0.25
  max:    31937.39
```

### 5.2 Feature Engineering from Dataset

**Step 3: Create Features Matching Your Entities**

```python
import pandas as pd
import numpy as np
from datetime import datetime, timedelta

# Load dataset
df = pd.read_csv('train_transaction.csv')

# Feature 1: Amount (direct mapping)
df['amount'] = df['TransactionAmt']

# Feature 2: Hour (extract from TransactionDT)
# TransactionDT is seconds since reference point
reference_date = datetime(2017, 12, 1)  # Adjust based on dataset
df['timestamp'] = df['TransactionDT'].apply(
    lambda x: reference_date + timedelta(seconds=x)
)
df['hour'] = df['timestamp'].dt.hour
df['day_of_week'] = df['timestamp'].dt.dayofweek
df['day_of_month'] = df['timestamp'].dt.day
df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)

# Feature 3: Transaction Type (map ProductCD)
# ProductCD values: W, C, R, H, S
transaction_type_map = {
    'W': 0,  # PAYMENT
    'C': 1,  # TRANSFER
    'R': 2,  # WITHDRAWAL
    'H': 3,  # DEPOSIT
    'S': 0,  # PAYMENT
}
df['transaction_type'] = df['ProductCD'].map(transaction_type_map)

# Feature 4: User ID (use card1 as proxy for user)
df['user_id'] = df['card1']

# Feature 5: User statistics (aggregate)
user_stats = df.groupby('user_id').agg({
    'TransactionID': 'count',          # Transaction count
    'TransactionAmt': ['mean', 'std'],  # Average amount
}).reset_index()
user_stats.columns = ['user_id', 'user_tx_count', 'user_avg_amount', 'user_std_amount']

df = df.merge(user_stats, on='user_id', how='left')

# Select final features for model
features = [
    'amount',
    'hour',
    'day_of_week',
    'day_of_month',
    'is_weekend',
    'transaction_type',
    'user_tx_count',
    'user_avg_amount',
    'user_std_amount',
]

X = df[features].fillna(0)  # Fill missing values
y = df['isFraud']

# Save preprocessed dataset
df_final = X.copy()
df_final['is_fraud'] = y
df_final.to_csv('preprocessed_fraud_dataset.csv', index=False)

print(f"Preprocessed dataset shape: {df_final.shape}")
print(f"Features: {features}")
```

### 5.3 Train Models from Preprocessed Dataset

**Step 4: Train PyTorch Model (for DJL)**

```python
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# Load preprocessed data
df = pd.read_csv('preprocessed_fraud_dataset.csv')

X = df.drop('is_fraud', axis=1).values
y = df['is_fraud'].values

# Split data
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

# Standardize features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Convert to PyTorch tensors
X_train_t = torch.FloatTensor(X_train)
y_train_t = torch.FloatTensor(y_train).reshape(-1, 1)
X_test_t = torch.FloatTensor(X_test)
y_test_t = torch.FloatTensor(y_test).reshape(-1, 1)

# Define neural network
class FraudDetectionNN(nn.Module):
    def __init__(self, input_size):
        super(FraudDetectionNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 16)
        self.fc4 = nn.Linear(16, 1)
        self.relu = nn.ReLU()
        self.sigmoid = nn.Sigmoid()
        self.dropout = nn.Dropout(0.3)
        
    def forward(self, x):
        x = self.relu(self.fc1(x))
        x = self.dropout(x)
        x = self.relu(self.fc2(x))
        x = self.dropout(x)
        x = self.relu(self.fc3(x))
        x = self.sigmoid(self.fc4(x))
        return x

# Train model
model = FraudDetectionNN(input_size=X_train.shape[1])
criterion = nn.BCELoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

epochs = 50
for epoch in range(epochs):
    optimizer.zero_grad()
    outputs = model(X_train_t)
    loss = criterion(outputs, y_train_t)
    loss.backward()
    optimizer.step()
    
    if (epoch + 1) % 10 == 0:
        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')

# Evaluate
model.eval()
with torch.no_grad():
    predictions = model(X_test_t)
    predicted_classes = (predictions > 0.5).float()
    accuracy = (predicted_classes == y_test_t).float().mean()
    print(f'Test Accuracy: {accuracy.item()*100:.2f}%')

# Save model
torch.save(model.state_dict(), 'fraud_detection_model.pt')
print("Model saved as fraud_detection_model.pt")

# Also save scaler
import joblib
joblib.dump(scaler, 'feature_scaler.pkl')
```

**Step 5: Train Scikit-learn Model (for ONNX)**

```python
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, roc_auc_score
from skl2onnx import convert_sklearn
from skl2onnx.common.data_types import FloatTensorType

# Train Random Forest
rf_model = RandomForestClassifier(
    n_estimators=100,
    max_depth=10,
    random_state=42,
    class_weight='balanced'  # Handle imbalanced classes
)

rf_model.fit(X_train, y_train)

# Evaluate
y_pred = rf_model.predict(X_test)
y_pred_proba = rf_model.predict_proba(X_test)[:, 1]

print("\nRandom Forest Performance:")
print(classification_report(y_test, y_pred))
print(f"ROC-AUC Score: {roc_auc_score(y_test, y_pred_proba):.4f}")

# Convert to ONNX
initial_type = [('float_input', FloatTensorType([None, X_train.shape[1]]))]
onnx_model = convert_sklearn(rf_model, initial_types=initial_type)

# Save ONNX model
with open("fraud_detection_model.onnx", "wb") as f:
    f.write(onnx_model.SerializeToString())

print("Model saved as fraud_detection_model.onnx")
```

**Step 6: Train TensorFlow Model**

```python
import tensorflow as tf
from tensorflow.keras import layers, models

# Build TensorFlow model
tf_model = models.Sequential([
    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),
    layers.Dropout(0.3),
    layers.Dense(32, activation='relu'),
    layers.Dropout(0.3),
    layers.Dense(16, activation='relu'),
    layers.Dense(1, activation='sigmoid')
])

tf_model.compile(
    optimizer='adam',
    loss='binary_crossentropy',
    metrics=['accuracy', tf.keras.metrics.AUC()]
)

# Train with class weights (handle imbalance)
class_weight = {0: 1.0, 1: 20.0}  # Fraud is 20x more important

history = tf_model.fit(
    X_train, y_train,
    validation_split=0.2,
    epochs=30,
    batch_size=256,
    class_weight=class_weight,
    verbose=1
)

# Evaluate
loss, accuracy, auc = tf_model.evaluate(X_test, y_test)
print(f"\nTensorFlow Model - Accuracy: {accuracy*100:.2f}%, AUC: {auc:.4f}")

# Save model
tf_model.save('fraud_detection_tf_model')
print("Model saved as fraud_detection_tf_model/")
```

---

## PART 6: UPDATING YOUR JAVA CODE

### 6.1 What Changes Are Needed?

**Current State:** Rule-based placeholder logic in detectors

**After Training Models:** Replace with actual model loading

### 6.2 Update DJL Detector (Load PyTorch Model)

**File:** `DJLFraudDetector.java`

```java
@PostConstruct
public void init() {
    try {
        log.info("Loading PyTorch fraud detection model...");
        
        // Load the trained PyTorch model
        Path modelPath = Paths.get("src/main/resources/models/fraud_detection_model.pt");
        
        Criteria<float[], float[]> criteria = Criteria.builder()
            .setTypes(float[].class, float[].class)
            .optModelPath(modelPath)
            .optEngine("PyTorch")
            .build();
        
        model = criteria.loadModel();
        log.info("PyTorch model loaded successfully");
        
    } catch (Exception e) {
        log.error("Failed to load PyTorch model", e);
        throw new ModelLoadException(MODEL_NAME, e);
    }
}

private double performInference(float[] features) throws Exception {
    // Use actual model prediction
    try (Predictor<float[], float[]> predictor = model.newPredictor()) {
        float[] output = predictor.predict(features);
        return output[0];  // Fraud probability
    }
}
```

### 6.3 Update ONNX Detector

**File:** `ONNXFraudDetector.java`

```java
@PostConstruct
public void init() {
    try {
        log.info("Loading ONNX fraud detection model...");
        env = OrtEnvironment.getEnvironment();
        
        // Load actual ONNX model
        String modelPath = "src/main/resources/models/fraud_detection_model.onnx";
        session = env.createSession(modelPath, new OrtSession.SessionOptions());
        
        log.info("ONNX model loaded successfully");
    } catch (Exception e) {
        log.error("Failed to load ONNX model", e);
        throw new ModelLoadException(MODEL_NAME, e);
    }
}

private double performInference(float[] features) throws Exception {
    // Create input tensor
    long[] shape = {1, features.length};
    OnnxTensor inputTensor = OnnxTensor.createTensor(env, 
        new float[][]{features}, shape);
    
    // Run inference
    Map<String, OnnxTensor> inputs = Map.of("float_input", inputTensor);
    OrtSession.Result result = session.run(inputs);
    
    // Extract output
    float[][] output = (float[][]) result.get(0).getValue();
    double confidence = output[0][0];
    
    // Cleanup
    inputTensor.close();
    result.close();
    
    return confidence;
}
```

### 6.4 Update TensorFlow Detector

**File:** `TensorFlowFraudDetector.java`

```java
private SavedModelBundle savedModelBundle;

@PostConstruct
public void init() {
    try {
        log.info("Loading TensorFlow fraud detection model...");
        
        // Load SavedModel
        String modelPath = "src/main/resources/models/fraud_detection_tf_model";
        savedModelBundle = SavedModelBundle.load(modelPath, "serve");
        
        log.info("TensorFlow model loaded successfully");
    } catch (Exception e) {
        log.error("Failed to load TensorFlow model", e);
        throw new ModelLoadException(MODEL_NAME, e);
    }
}

private double performInference(float[] features) throws Exception {
    // Create input tensor
    Tensor<?> inputTensor = Tensor.create(new float[][]{features});
    
    // Run inference
    Tensor<?> outputTensor = savedModelBundle.session()
        .runner()
        .feed("serving_default_input", inputTensor)
        .fetch("StatefulPartitionedCall")
        .run()
        .get(0);
    
    // Extract output
    float[][] output = new float[1][1];
    outputTensor.copyTo(output);
    
    // Cleanup
    inputTensor.close();
    outputTensor.close();
    
    return output[0][0];
}
```

---

## PART 7: SUMMARY & CHECKLIST

### 7.1 Quick Answers to Your Questions

| Question | Answer |
|----------|--------|
| **Which dataset to use?** | IEEE-CIS Fraud Detection (590K transactions, 434 features) |
| **Do I need separate datasets for each model?** | NO - Use ONE dataset, train 3 different models |
| **Required columns?** | `id`, `amount`, `timestamp`, `is_fraud` |
| **Is it a problem if dataset has more columns?** | NO - Extra columns are GOOD, use feature selection |
| **Column names don't match my entities?** | NO PROBLEM - Map during feature extraction |
| **Minimum dataset size?** | 10,000+ rows, 100+ fraud cases for testing; 100,000+ rows for production |

### 7.2 Implementation Checklist

**Phase 1: Setup (Week 1)**
- [ ] Download IEEE-CIS dataset from Kaggle
- [ ] Explore dataset structure and features
- [ ] Preprocess features to match your Transaction entity
- [ ] Split into train/validation/test sets

**Phase 2: Model Training (Week 2)**
- [ ] Train PyTorch model ‚Üí export to .pt file
- [ ] Train Scikit-learn model ‚Üí export to .onnx file
- [ ] Train TensorFlow model ‚Üí export to SavedModel
- [ ] Evaluate all 3 models on test set
- [ ] Save feature scaler (StandardScaler)

**Phase 3: Integration (Week 3)**
- [ ] Copy trained models to `src/main/resources/models/`
- [ ] Update `DJLFraudDetector` to load PyTorch model
- [ ] Update `ONNXFraudDetector` to load ONNX model
- [ ] Update `TensorFlowFraudDetector` to load TF model
- [ ] Update `extractFeatures()` to match training features
- [ ] Test with sample transactions

**Phase 4: Validation (Week 4)**
- [ ] Test fraud detection on known fraud cases
- [ ] Test on legitimate transactions
- [ ] Measure accuracy, precision, recall
- [ ] Tune ensemble weights if needed
- [ ] Deploy to production

**Phase 5: Long-term (Months 6-12)**
- [ ] Collect your own transaction data
- [ ] Manually label fraud cases
- [ ] Retrain models on YOUR data
- [ ] Compare accuracy: Kaggle data vs Your data
- [ ] Iterate and improve

---

## PART 8: FINAL RECOMMENDATIONS

### 8.1 Best Path Forward

**For Your Current Project:**

1. **Use IEEE-CIS Dataset** (590K transactions)
   - Download today
   - High-quality real-world data
   - Train production-ready models

2. **Start with Simple Features** (10-15)
   - Amount, hour, day_of_week, transaction_type
   - User statistics (count, average)
   - Get 80% accuracy quickly

3. **Iterate and Add Features**
   - After initial deployment
   - Monitor false positives/negatives
   - Add more features (device, IP, velocity)
   - Retrain models
   - Improve to 90%+ accuracy

4. **Collect Your Own Data**
   - Run system for 6-12 months
   - Build Tunisian SME-specific dataset
   - Ultimate accuracy: 95%+

### 8.2 Expected Accuracy

| Data Source | Expected Accuracy | Time to Achieve |
|-------------|------------------|-----------------|
| Rule-based (current) | 60-70% | ‚úÖ Done |
| IEEE-CIS dataset (10 features) | 80-85% | 2 weeks |
| IEEE-CIS dataset (50 features) | 88-92% | 1 month |
| Your own data (after 1 year) | 93-97% | 12 months |

**Note:** These are ensemble accuracies (3 models combined)

---

## CONCLUSION

You now have a **complete blueprint** for dataset selection and model training:

‚úÖ **Dataset:** Use IEEE-CIS Fraud Detection (590K transactions)  
‚úÖ **Models:** Train one PyTorch, one Scikit-learn, one TensorFlow model from SAME dataset  
‚úÖ **Features:** Start with 10 basic features, expand to 50+ over time  
‚úÖ **Column Mapping:** Feature extraction bridges dataset ‚Üî your entities  
‚úÖ **Size:** 100K+ transactions for production  
‚úÖ **Long-term:** Collect your own Tunisian SME data  

**Next Steps:**
1. Download IEEE-CIS dataset
2. Follow PART 5 (training scripts)
3. Follow PART 6 (update Java code)
4. Test and deploy!

**Questions?** Everything is explained above. Read carefully! üìö
